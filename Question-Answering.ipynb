{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Trong notebook này, bằng cách sử dụng Transformer, chúng ta thực hiện bài toán như một **question-answring system**.\n",
    "\n",
    "Code và notebook được thiết kế rõ ràng để hiểu cho người mới bắt đầu nhưng hy vọng cũng có ích cho các Kaggler nâng cao.\n",
    "\n",
    "Bất kỳ bình luận / phản hồi là rất đánh giá cao.  Tuyên bố từ chối trách nhiệm: công việc đang được tiến hành, tôi sẽ sớm thêm các tài nguyên và nhận xét mới.\n",
    "\n",
    "# 1. Problem formulation\n",
    "Chúng tôi xây dựng bài toán question answring: cho một câu hỏi và mộ ngữ cảnh, chúng tôi huấn luyện transformer để tìm **answer** trong cột **text** (the context).\n",
    "\n",
    "Chúng tôi có:\n",
    "1. Question: **sentiment** column (**positive** hoặc **negative**)\n",
    "2. Context: **text** column\n",
    "3. Answer: **selected_text** column\n",
    "\n",
    "# 2. Getting started with QA\n",
    "# 3. Learning QA from scratch\n",
    "# 4. Model: DistilBERT + SquAD\n",
    "# 5. Dataset publicly avaiable\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.1 DistilBERT + SQuAD model\n",
    "Bởi vì sổ ghi chép của Tweet Sentiment Extraction phải tắt internet, tôi đã tải xuống và lưu trữ mô hình máy biến áp trong tập dữ liệu Kaggle công khai: Các mô hình distilBERT được đào tạo trước của Transformers.  Trong tương lai, tôi dự định tải tất cả các mô hình đã được đào tạo trước của distilBERT lên cùng một tập dữ liệu để chúng tôi có thể dễ dàng thử nghiệm với nhiều mô hình và cấu hình."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "sub_df = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train_df)\n",
    "test = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "source": [
    "```\n",
    "train_data = [\n",
    "    {\n",
    "        'context': \"This tweet sentiment extraction challenge is great\",\n",
    "        'qas': [\n",
    "            {\n",
    "                'id': \"00001\",\n",
    "                'question': \"positive\",\n",
    "                'answers': [\n",
    "                    {\n",
    "                        'text': \"is great\",\n",
    "                        'answer_start': 43\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    ]\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "neutral <class 'str'>\n",
      "CPU times: user 735 ms, sys: 18.4 ms, total: 754 ms\n",
      "Wall time: 852 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\" Pre training data in QA-compatible format\"\"\"\n",
    "def find_all(input_str, search_str):\n",
    "    l1 = []\n",
    "    length = len(input_str)\n",
    "    index = 0\n",
    "    while index < length:\n",
    "        i = input_str.find(search_str, index)\n",
    "        if i==-1:\n",
    "            return l1\n",
    "        l1.append(i)\n",
    "        index = i+1\n",
    "    return l1\n",
    "\n",
    "def do_qa_train(train):\n",
    "    output = []\n",
    "    for line in train:\n",
    "        context = line[1]\n",
    "\n",
    "        qas = []\n",
    "        question = line[-1]\n",
    "        qid = line[0]\n",
    "        answers = []\n",
    "        answer = line[2]\n",
    "\n",
    "        if type(answer) != str or type(context) != str or type(question) != str:\n",
    "            print(context, type(context))\n",
    "            print(answer, type(answer))\n",
    "            print(question, type(question))\n",
    "            continue\n",
    "\n",
    "        answer_starts = find_all(context, answer)\n",
    "        for answer_start in answer_starts:\n",
    "            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n",
    "            break\n",
    "        qas.append({'question': question, 'id': qid, 'im_impossible': False, 'answers': answers})\n",
    "        output.append({'context': context.lower(), 'qas': qas})\n",
    "\n",
    "    return output\n",
    "\n",
    "qa_train = do_qa_train(train)\n",
    "\n",
    "with open('./data/train.json', 'w') as outfile:\n",
    "    json.dump(qa_train, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 200 ms, sys: 3.55 ms, total: 204 ms\nWall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "Prepare testing data in QA-compatible format\n",
    "\"\"\"\n",
    "\n",
    "def do_qa_test(test):\n",
    "    output = []\n",
    "    for line in test:\n",
    "        context = line[1]\n",
    "        qas = []\n",
    "        question = line[-1]\n",
    "        qid = line[0]\n",
    "        if type(context) != str or type(question) != str:\n",
    "            print(context, type(context))\n",
    "            print(answer, type(answer))\n",
    "            print(question, type(question))\n",
    "            continue\n",
    "        answers = []\n",
    "        answers.append({'answer_start': 1000000, 'text': '__None__'})\n",
    "        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n",
    "        output.append({'context': context.lower(), 'qas': qas})\n",
    "    return output\n",
    "\n",
    "qa_test = do_qa_test(test)\n",
    "\n",
    "with open('data/test.json', 'w') as outfile:\n",
    "    json.dump(qa_test, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at ./distilbert-base-uncased-distilled-squad/ and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.question_answering import QuestionAnsweringModel\n",
    "MODEL_PATH = './distilbert-base-uncased-distilled-squad/'\n",
    "\n",
    "model = QuestionAnsweringModel('distilbert',\n",
    "MODEL_PATH,\n",
    "args = {'reprocess_input_data': True,\n",
    "                                     'overwrite_output_dir': True,\n",
    "                                     'learning_rate': 5e-5,\n",
    "                                     'num_train_epochs': 3,\n",
    "                                     'max_seq_length': 192,\n",
    "                                     'doc_stride': 64,\n",
    "                                     'fp16': False,\n",
    "                                    },\n",
    "                              use_cuda=use_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "convert squad examples to features:   0%|          | 0/27480 [00:00<?, ?it/s]/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "convert squad examples to features: 100%|██████████| 27480/27480 [00:12<00:00, 2238.81it/s]\n",
      "add example index and unique id: 100%|██████████| 27480/27480 [00:00<00:00, 1098619.56it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=3.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4aaf370f571f4d1488e05f8cfa20d864"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Running Epoch 0 of 3'), FloatProgress(value=0.0, max=3435.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7152d7c94d80417fb3287a080e86db24"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/thang/env/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/home/thang/env/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Running Epoch 1 of 3'), FloatProgress(value=0.0, max=3435.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8e7186c23d74e108d748f5589e34b14"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Running Epoch 2 of 3'), FloatProgress(value=0.0, max=3435.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f9c94167a7143f6b903e94083a17aee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10305, 0.7631413049680036)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.train_model('data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "convert squad examples to features:   0%|          | 0/3534 [00:00<?, ?it/s]/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "/home/thang/env/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1324: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
      "  FutureWarning,\n",
      "convert squad examples to features: 100%|██████████| 3534/3534 [01:33<00:00, 37.63it/s]\n",
      "add example index and unique id: 100%|██████████| 3534/3534 [00:00<00:00, 1158021.12it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Running Prediction'), FloatProgress(value=0.0, max=442.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0c57c09101549fdac8b74400a57204e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "File submitted successfully.\n",
      "CPU times: user 1min 6s, sys: 1.01 s, total: 1min 7s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = model.predict(qa_test)\n",
    "predictions_df = pd.DataFrame.from_dict(predictions[0])\n",
    "\n",
    "sub_df['selected_text'] = predictions_df['answer']\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"File submitted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}