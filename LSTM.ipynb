{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "**Phân tích cảm xúc là việc giải thích và phân loại cảm xúc (tích cực, tiêu cực và trung tính) trong dữ liệu văn bản bằng kỹ thuật phân tích văn bản.  Phân tích tình cảm cho phép các doanh nghiệp xác định cảm xúc của khách hàng đối với sản phẩm, thương hiệu hoặc dịch vụ trong các cuộc trò chuyện và phản hồi trực tuyến.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Ưu điểm của việc phân tích cảm xúc\n",
    "- Bằng cách sử dụng phân tích cảm xúc, bạn đánh giá cảm nhận của khách hàng về các lĩnh vực khác nhau của doanh nghiệp mà không cần phải đọc hàng nghìn nhận xét của khách hàng cùng một lúc.\n",
    "- Nếu bạn có hàng nghìn hoặc thậm chí hàng chục nghìn câu trả lời khảo sát mỗi tháng, thì không thể có một người đọc tất cả các câu trả lời này và có một thước đo không khách quan và nhất quán về tình cảm của khách hàng.  Bằng cách sử dụng phân tích tình cảm và tự động hóa quy trình này, bạn có thể dễ dàng đi sâu vào các phân khúc khách hàng khác nhau của doanh nghiệp mình và hiểu rõ hơn về tình cảm trong các phân khúc này."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Nhược điểm của việc sử dụng phân tích cảm xúc\n",
    "- Mặc dù phân tích cảm xúc là hữu ích, nhưng chúng tôi không tin rằng nó là một sự thay thế hoàn toàn cho việc đọc các câu trả lời khảo sát, vì bản thân các nhận xét thường có những sắc thái hữu ích.  Việc phân tích cảm xúc có thể giúp bạn thêm ở đâu là xác định bạn nên đọc những nhận xét nào trong số những nhận xét này, chẳng hạn như cho phép bạn tập trung vào những nhận xét tiêu cực nhất."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Cách phân tích cảm xúc thực sự hoạt động\n",
    "- Phân tích tình cảm truyền thống bao gồm việc sử dụng các từ điển tham khảo về mức độ tích cực của các từ nhất định và sau đó tính điểm trung bình của những điểm này như cảm xúc của văn bản đó.\n",
    "- Bước tiếp theo từ đây là sử dụng một mô hình ML đơn giản để phân loại.  Điều này được thực hiện bằng cách tạo ra các \"đặc trưng\" từ văn bản sau đó sử dụng các đặc trưng này để dự đoán một \"nhãn\".  Một ví dụ về việc tạo các tính năng là chia nhỏ văn bản thành các từ và sau đó sử dụng các từ này và tần số của chúng trong văn bản làm đặc truwng."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nan Values\n",
    "X = train_df.dropna()\n",
    "\n",
    "# Get training data\n",
    "X = train_df.drop('sentiment', axis=1)\n",
    "\n",
    "# Get target label\n",
    "y = train_df['sentiment']"
   ]
  },
  {
   "source": [
    "# Onehot Representation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/thang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Onehot Representation\n",
    "\n",
    "messages = X.copy()\n",
    "\n",
    "# The reset_index() function is used to generate a new DataFrame or Series with the index reset\n",
    "messages.reset_index(inplace = True)\n",
    "\n",
    "# Downloading stop words\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preprocessing\n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, len(messages)):\n",
    "    # replace with space words other than a-1, A-Z\n",
    "    \n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(messages['text'][i]))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "onehot_repr = [one_hot(words, voc_size) for words in corpus]"
   ]
  },
  {
   "source": [
    "# Embedding Representation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making all sentences of same length\n",
    "sent_length = 30\n",
    "embedded_docs = pad_sequences(onehot_repr, padding = 'pre', maxlen = sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the numberof labels\n",
    "num_labels = len(set(train_df['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "source": [
    "# Constructing LSTM model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 30, 40)            200000    \n_________________________________________________________________\nlstm (LSTM)                  (None, 100)               56400     \n_________________________________________________________________\ndense (Dense)                (None, 3)                 303       \n=================================================================\nTotal params: 256,703\nTrainable params: 256,703\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "\n",
    "## Creating model\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(num_labels,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# encode label to int\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_final = np.array(embedded_docs)\n",
    "y_final = np.array(y)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_final = to_categorical(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "288/288 [==============================] - 2s 8ms/step - loss: 0.9000 - accuracy: 0.5752 - val_loss: 0.7858 - val_accuracy: 0.6595\n",
      "Epoch 2/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.7252 - accuracy: 0.6955 - val_loss: 0.7604 - val_accuracy: 0.6741\n",
      "Epoch 3/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.6729 - accuracy: 0.7234 - val_loss: 0.7583 - val_accuracy: 0.6741\n",
      "Epoch 4/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.6417 - accuracy: 0.7384 - val_loss: 0.7668 - val_accuracy: 0.6754\n",
      "Epoch 5/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.6210 - accuracy: 0.7514 - val_loss: 0.7708 - val_accuracy: 0.6747\n",
      "Epoch 6/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.6013 - accuracy: 0.7597 - val_loss: 0.7923 - val_accuracy: 0.6664\n",
      "Epoch 7/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.5829 - accuracy: 0.7673 - val_loss: 0.7875 - val_accuracy: 0.6723\n",
      "Epoch 8/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.5615 - accuracy: 0.7799 - val_loss: 0.8340 - val_accuracy: 0.6534\n",
      "Epoch 9/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.5379 - accuracy: 0.7919 - val_loss: 0.8158 - val_accuracy: 0.6675\n",
      "Epoch 10/10\n",
      "288/288 [==============================] - 2s 7ms/step - loss: 0.5106 - accuracy: 0.8052 - val_loss: 0.8572 - val_accuracy: 0.6631\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f745c338ac8>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 10, batch_size = 64)"
   ]
  },
  {
   "source": [
    "# Putting all the pre-processing steps done for training in one function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_x_y(X):\n",
    "    \n",
    "    # Drop Nan Values\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    messages = X.copy()\n",
    "\n",
    "    messages.reset_index(inplace = True)\n",
    "\n",
    "    # Dataset Preprocessing\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    for i in range(0, len(messages)):\n",
    "        # replace with space words other than a-1, A-Z\n",
    "\n",
    "        review = re.sub('[^a-zA-Z]', ' ', str(messages['text'][i]))\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "\n",
    "        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "\n",
    "    # vocabulray size\n",
    "    voc_size = 5000\n",
    "\n",
    "    onehot_repr = [one_hot(words, voc_size) for words in corpus]\n",
    "\n",
    "    # Embedding Representation\n",
    "    # making all sentences of same length\n",
    "    sent_length = 30\n",
    "    embedded_docs = pad_sequences(onehot_repr, padding = 'pre', maxlen = sent_length)\n",
    "\n",
    "    X_final = np.array(embedded_docs)\n",
    "    \n",
    "    \n",
    "    return X_final, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test data and pre-processing\n",
    "test_df = pd.read_csv('./data//test.csv')\n",
    "X_test,X_test_drop = return_x_y(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-572e34c12547>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\nInstructions for updating:\nPlease use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "# making prediction\n",
    "y_pred_test = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 0, 2, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3534, 3534)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "len(X_test_drop['textID']), len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = X_test_drop['textID']\n",
    "df_sub['text'] = X_test_drop['text']\n",
    "df_sub['sentiment_predicted'] = le.inverse_transform(y_pred_test)\n",
    "df_sub['sentiment_actual'] = X_test_drop['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('gender_submission.csv', index=False)"
   ]
  }
 ]
}